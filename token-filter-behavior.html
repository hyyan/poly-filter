<link rel="import" href="../polymer/polymer.html">

<script>
(function() {
  'use strict';
  /**
   * `Polymer.TokenFilterBehavior` is a behavior implementing fast,
   * powerfull, and intuitive client side filtering of items.
   *
   * @polymerBehavior Polymer.TokenFilterBehavior
   */
  Polymer.TokenFilterBehavior = {

    properties: {

      /**
       * Array ot items (Object or not) to filter.
       */
      arrayToFilter: {
        type: Array,
        value: function() {
          return [];
        }
      },

      /**
       * Tokenized and flattened `arrayToFilter` to boost filtering performance.
       */
      _processedArray: {
        type: Array,
        computed: '_processArray(arrayToFilter, itemPropertiesToFilter, filterTokenizerRegExp, filterMaxDepth, stopWords)'
      },

      /**
       * The output : All the items of `arrayToFilter` that survived filtering.
       */
      filteredArray: {
        type: Array,
        readOnly: true,
        notify: true
      },

      /**
       * The String used to filter the collection of items `arrayToFilter`.
       */
      filter: {
        type: String,
        value: ''
      },

      /**
       * Minimum length of the `filter` String to be taken into account.
       */
      filterMinLength: {
        type: Number,
        value: 2
      },

      /**
       * Debounce delay (in `ms`) before filtering when the `filter` String is changed.
       */
      filterDebounceDelay: {
        type: Number,
        value: 200
      },

      /**
       * List of the item's properties to take into account for the filtering.
       * If empty, item's in `arrayToFilter` will be filtered based on ``all`` their properties.
       *
       * Example:
       * If the items in `arrayToFilter` represents countries with these properties :
       *     
       *     {'code': 'FR', 'name': 'France', 'language': 'French'}
       *     
       * and you only want to filter your array based on the `name' and `code`, you must set
       * `itemPropertiesToFilter` to :
       *     
       *     ['code', 'name']
       */
      itemPropertiesToFilter: {
        type: Array,
        value: function() {
          return [];
        }
      },

      /**
       * Maximum depth (number) of sub-properties in items of `arrayToFilter` to consider
       * when filtering.
       *
       * Example:
       * If the items in `arrayToFilter` are objet like these :
       *     
       *     {'level_1_prop':
       *       {'level_2_prop':
       *         {'level_3_prop':
       *           {'level_4_prop': 'hello world'}}}}
       *     
       * and `filterMaxDepth` is set to `2`, the `level_3_prop` and `level_4_prop`
       * will never be inspected during filtering.
       */
      filterMaxDepth: {
        type: Number,
        value: 1
      },

      /**
       * RegExp used to tokenize `filter` and each properties of the items
       * to filter (`arrayToFilter`).
       * @type {RegExp}
       */
      filterTokenizerRegExp: {
        type: RegExp,
        value: function() {
          return /[.?!,\\/ |-]/ig;
        }
      },

      /**
       * Array of words that should be ignored during the filtering process.
       */
      stopWords: {
        type: Array,
        value: function() {
          return [];
        }
      },

      /**
       * Case insensitive Logical OR operator.
       *
       * Example:
       * If the logical OR operator is set to 'or' and the `filter` is 'united ki or swed',
       * then a filtered country list will retain both 'United Kingdom' and 'Sweden'.
       */
      logicalOr: {
        type: String,
        value: 'or'
      }
    },

    observers: [
      '_generateFilteredArray(filter, _processedArray, filterMinLength, filterDebounceDelay, logicalOr)'
    ],

    _generateFilteredArray: function(filter, _processedArray, filterMinLength, filterDebounceDelay, logicalOr) {
      if (!this.filterTokenizerRegExp) {
        throw 'filterTokenizerRegExp must not be undefined';
      }
      this.stopWords = this.stopWords || [];

      this.debounce('_generateFilteredArray' + this.localName, function() {
        //console.time('_generateFilteredArray ' + filter);
        if (filter && filter.length >= (filterMinLength || 2)) {
          var result = [], filterTokens, itemTokens;
          var filterParts = logicalOr ? filter.toLowerCase().split(logicalOr.toLowerCase()) : [filter];
          for (var i = 0, l = filterParts.length; i < l; i++) {
            if (filterParts[i].trim()) {
              filterTokens = this._processValue(filterParts[i], this.filterTokenizerRegExp, this.stopWords);

              result = this._concat(result, this.arrayToFilter.filter(function(obj, j) {
                itemTokens = _processedArray[j];
                return filterTokens.every(function(filterToken) {

                  return filterToken && itemTokens.some(function(value) {
                    return value.startsWith(filterToken);
                  });
                });
              }));
            }
          }
          this._setFilteredArray(result);
        } else {
          this._setFilteredArray(this.arrayToFilter);
        }
        //console.timeEnd('_generateFilteredArray ' + filter);
      }, !isNaN(filterDebounceDelay) && filterDebounceDelay > -1 ? filterDebounceDelay : 200);
    },

    _processArray: function(arrayToFilter, itemPropertiesToFilter, filterTokenizerRegExp, filterMaxDepth, stopWords) {
      //console.time('_processArray');
      if (!filterTokenizerRegExp) {
        throw 'filterTokenizerRegExp must not be undefined';
      }
      if (!(filterMaxDepth > -1)) {
        throw 'filterMaxDepth (' + filterMaxDepth + ') must be a valid number >= 0';
      }
      itemPropertiesToFilter = itemPropertiesToFilter || [];
      stopWords = stopWords || [];
      
      var result = [];
      if (arrayToFilter) {
        for (var i = 0, l = arrayToFilter.length; i < l; i++) {
          var item = arrayToFilter[i];
          if (item) {
            result.push(this._processItem(item, itemPropertiesToFilter, filterTokenizerRegExp, 0, filterMaxDepth, stopWords));
          }
        }
      }
      //console.timeEnd('_processArray');
      return result;
    },

    _processItem: function(item, itemPropertiesToFilter, filterTokenizerRegExp, depth, filterMaxDepth, stopWords) {
      if (typeof item === 'string' || typeof item === 'number' || typeof item === 'boolean') {
        return this._processValue(item, filterTokenizerRegExp, stopWords);
      } else {
        var flattenedItemTokens = [];
        if (item) {
          if (item.constructor === Array) {
            for (var i = 0, l = item.length; i < l; i++) {
              flattenedItemTokens = this._concat(flattenedItemTokens, this._processItem(item[i], itemPropertiesToFilter, filterTokenizerRegExp, depth + 1, filterMaxDepth, stopWords));
            }
          }
          else if (depth <= filterMaxDepth) {
            var filterAllProps = !itemPropertiesToFilter || !itemPropertiesToFilter.length;
            for (var propName in item) {
              if (!filterAllProps && itemPropertiesToFilter.indexOf(propName) < 0) {
                continue;
              } else {
                flattenedItemTokens = this._concat(flattenedItemTokens, this._processItem(item[propName], itemPropertiesToFilter, filterTokenizerRegExp, depth + 1, filterMaxDepth, stopWords));
              }
            }
          }
        }
        return flattenedItemTokens;
      }
    },

    _processValue: function(value, filterTokenizerRegExp, stopWords) {
      // Safety checks
      if (value === undefined || value === null || (value === NaN)) {
        return undefined;
      }
      // Split value into tokens
      var tokens = ('' + value).toLowerCase().split(filterTokenizerRegExp);
      // Processing token, removing empty ones and stop words
      var tt, me = this;
      tokens = tokens.reduce(function(memo, t) {
        tt = me._processToken(t);
        if (tt && stopWords.indexOf(tt)) {
          memo.push(tt);
        }
        return memo;
      }, []);
      return tokens;
    },

    _processToken: function(token) {
      return token.trim();
    },

    _concat: function(dest, values) {
      if (values) {
        return dest.concat(values);
      }
      return dest;
    }
  };
})();
</script>